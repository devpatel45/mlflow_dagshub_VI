{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c8696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82d01ef",
   "metadata": {},
   "source": [
    "### Preparing X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7409ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"survey_results_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4426b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['respondent_id', 'price_range'], axis='columns')\n",
    "Y = df['price_range']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c75df4",
   "metadata": {},
   "source": [
    "### Data Splitting and Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d524e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267be8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"age_group\", \"income_levels\", \"health_concerns\", \n",
    "              \"consume_frequency(weekly)\", \"preferable_consumption_size\"]\n",
    "\n",
    "\n",
    "# This code will ensure the uniformity in the data so no error are put out!\n",
    "for col in label_cols:\n",
    "    X_train[col] = X_train[col].astype(str).str.strip()\n",
    "    X_test[col] = X_test[col].astype(str).str.strip()\n",
    "\n",
    "    X_train[col] = X_train[col].str.lower()\n",
    "    X_test[col] = X_test[col].str.lower()\n",
    "\n",
    "\n",
    "X_train.columns = X_train.columns.str.replace(' ', '_')\n",
    "X_test.columns = X_test.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eccc38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will print any unseen column by the test data\n",
    "for col in label_cols:\n",
    "    train_vals = set(X_train[col].astype(str).unique())\n",
    "    test_vals = set(X_test[col].astype(str).unique())\n",
    "    diff = test_vals - train_vals\n",
    "    if diff:\n",
    "        print(f\"Column: {col} — Unseen in train: {diff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6700fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"age_group\", \"income_levels\", \"health_concerns\", \n",
    "              \"consume_frequency(weekly)\", \"preferable_consumption_size\"]\n",
    "\n",
    "# Initializes a dictionary to store encoders (optional, but useful)\n",
    "label_encoders = {}\n",
    "\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    label_encoders[col] = le # Save if you need to inverse transform later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93134877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_cols:\n",
    "    X_test[col] = label_encoders[col].transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686cc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "Y_test = le.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef07c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = list(X_train.drop(label_cols, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4aee048",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_array_train = oe.fit_transform(X_train[one_hot_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce364708",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df_train = pd.DataFrame(encoded_array_train, columns=oe.get_feature_names_out(one_hot_cols), index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93075e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=one_hot_cols, inplace=True)\n",
    "X_train = pd.concat([X_train, encoded_df_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbad37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_array_test = oe.transform(X_test[one_hot_cols])\n",
    "encoded_df_test = pd.DataFrame(encoded_array_test, columns=oe.get_feature_names_out(one_hot_cols), index=X_test.index)\n",
    "X_test.drop(columns=one_hot_cols, inplace=True)\n",
    "X_test = pd.concat([X_test, encoded_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c07ff",
   "metadata": {},
   "source": [
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "184e881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine (SVM)\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f13e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Beverage Price Prediction Tracking\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3acf9355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************** GAUSSIAN NAIVE BAYES ********************\n",
      "✅ Accuracy Score: 0.4541\n",
      "\n",
      "📊 Classification Report:\n",
      "\n",
      "              precision  recall  f1-score    support\n",
      "0                0.2352  0.3000    0.2637  1930.0000\n",
      "1                0.6067  0.0243    0.0467  2223.0000\n",
      "2                0.8083  0.7757    0.7917  2430.0000\n",
      "3                0.3388  0.9746    0.5028   906.0000\n",
      "accuracy         0.4541  0.4541    0.4541     0.4541\n",
      "macro avg        0.4973  0.5187    0.4012  7489.0000\n",
      "weighted avg     0.5440  0.4541    0.3995  7489.0000\n",
      "****************************************************************\n",
      "\n",
      "******************** LOGISTIC REGRESSION ********************\n",
      "✅ Accuracy Score: 0.8151\n",
      "\n",
      "📊 Classification Report:\n",
      "\n",
      "              precision  recall  f1-score    support\n",
      "0                0.7540  0.7736    0.7637  1930.0000\n",
      "1                0.7706  0.7859    0.7782  2223.0000\n",
      "2                0.9100  0.8992    0.9046  2430.0000\n",
      "3                0.8074  0.7494    0.7773   906.0000\n",
      "accuracy         0.8151  0.8151    0.8151     0.8151\n",
      "macro avg        0.8105  0.8020    0.8059  7489.0000\n",
      "weighted avg     0.8160  0.8151    0.8154  7489.0000\n",
      "***************************************************************\n",
      "\n",
      "******************** SUPPORT VECTOR MACHINE (SVM) ********************\n",
      "✅ Accuracy Score: 0.8880\n",
      "\n",
      "📊 Classification Report:\n",
      "\n",
      "              precision  recall  f1-score   support\n",
      "0                0.8697  0.8580    0.8638  1930.000\n",
      "1                0.8498  0.8754    0.8624  2223.000\n",
      "2                0.9408  0.9280    0.9343  2430.000\n",
      "3                0.8831  0.8753    0.8792   906.000\n",
      "accuracy         0.8880  0.8880    0.8880     0.888\n",
      "macro avg        0.8858  0.8842    0.8849  7489.000\n",
      "weighted avg     0.8885  0.8880    0.8881  7489.000\n",
      "************************************************************************\n",
      "\n",
      "******************** RANDOM FOREST ********************\n",
      "✅ Accuracy Score: 0.8924\n",
      "\n",
      "📊 Classification Report:\n",
      "\n",
      "              precision  recall  f1-score    support\n",
      "0                0.8804  0.8658    0.8730  1930.0000\n",
      "1                0.8461  0.8830    0.8642  2223.0000\n",
      "2                0.9389  0.9288    0.9338  2430.0000\n",
      "3                0.9135  0.8742    0.8934   906.0000\n",
      "accuracy         0.8924  0.8924    0.8924     0.8924\n",
      "macro avg        0.8947  0.8880    0.8911  7489.0000\n",
      "weighted avg     0.8932  0.8924    0.8926  7489.0000\n",
      "*********************************************************\n",
      "\n",
      "******************** XGBOOST ********************\n",
      "✅ Accuracy Score: 0.9204\n",
      "\n",
      "📊 Classification Report:\n",
      "\n",
      "              precision  recall  f1-score    support\n",
      "0                0.9125  0.8969    0.9046  1930.0000\n",
      "1                0.8920  0.9105    0.9012  2223.0000\n",
      "2                0.9549  0.9498    0.9523  2430.0000\n",
      "3                0.9161  0.9161    0.9161   906.0000\n",
      "accuracy         0.9204  0.9204    0.9204     0.9204\n",
      "macro avg        0.9189  0.9183    0.9186  7489.0000\n",
      "weighted avg     0.9206  0.9204    0.9205  7489.0000\n",
      "***************************************************\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 22467, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.343386\n",
      "[LightGBM] [Info] Start training from score -1.228925\n",
      "[LightGBM] [Info] Start training from score -1.126779\n",
      "[LightGBM] [Info] Start training from score -2.100810\n",
      "\n",
      "******************** LIGHTGBM ********************\n",
      "✅ Accuracy Score: 0.9201\n",
      "\n",
      "📊 Classification Report:\n",
      "\n",
      "              precision  recall  f1-score    support\n",
      "0                0.9081  0.8855    0.8966  1930.0000\n",
      "1                0.8852  0.9195    0.9020  2223.0000\n",
      "2                0.9614  0.9543    0.9579  2430.0000\n",
      "3                0.9244  0.9040    0.9141   906.0000\n",
      "accuracy         0.9201  0.9201    0.9201     0.9201\n",
      "macro avg        0.9198  0.9158    0.9177  7489.0000\n",
      "weighted avg     0.9206  0.9201    0.9202  7489.0000\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    report_dict = classification_report(Y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "    print(f\"\\n{'*' * 20} {name.upper()} {'*' * 20}\")\n",
    "    print(f\"✅ Accuracy Score: {accuracy:.4f}\\n\")\n",
    "    print(\"📊 Classification Report:\\n\")\n",
    "    print(report_df.round(4))\n",
    "    print(\"*\" * (44 + len(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c234b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 13:52:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Gaussian Naive Bayes at: http://127.0.0.1:5000/#/experiments/367472464984165969/runs/46854396004b49c1813ca99a1b835a49\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/367472464984165969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 13:52:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/367472464984165969/runs/bb2527dd7a3d47a9bcb938fc95079288\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/367472464984165969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 13:52:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Support Vector Machine (SVM) at: http://127.0.0.1:5000/#/experiments/367472464984165969/runs/2cc73e61fadf4a52bc9cc9464dc656c8\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/367472464984165969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 13:52:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/367472464984165969/runs/ebe81cba3b354b64bd646b9babe7f428\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/367472464984165969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bksdc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [13:52:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/05/13 13:52:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBoost at: http://127.0.0.1:5000/#/experiments/367472464984165969/runs/8075b5a3f1e14ba8895c7788ed9ddad1\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/367472464984165969\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 22467, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.343386\n",
      "[LightGBM] [Info] Start training from score -1.228925\n",
      "[LightGBM] [Info] Start training from score -1.126779\n",
      "[LightGBM] [Info] Start training from score -2.100810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 13:53:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LightGBM at: http://127.0.0.1:5000/#/experiments/367472464984165969/runs/b28cb7ded2804a849788d4b7f5a0a069\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/367472464984165969\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Fit and predict\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "        # Log model-specific parameters if needed\n",
    "        if hasattr(model, 'get_params'):\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "        # Log accuracy\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log the model (framework-specific for LightGBM/XGBoost)\n",
    "        if name == \"XGBoost\":\n",
    "            mlflow.xgboost.log_model(model, artifact_path=\"model\")\n",
    "        elif name == \"LightGBM\":\n",
    "            mlflow.lightgbm.log_model(model, artifact_path=\"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f5e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
